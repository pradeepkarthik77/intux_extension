{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping CB.EN.U4CSE20402 as it's already processed.\n",
      "Skipping CB.EN.U4CSE20403 as it's already processed.\n",
      "Skipping CB.EN.U4CSE20421 as it's already processed.\n",
      "Skipping CB.EN.U4CSE20425 as it's already processed.\n",
      "Skipping CB.EN.U4CSE20429 as it's already processed.\n",
      "Skipping CB.EN.U4CSE20431 as it's already processed.\n",
      "Skipping CB.EN.U4CSE20435 as it's already processed.\n",
      "Skipping CB.EN.U4CSE20436 as it's already processed.\n",
      "Skipping CB.EN.U4CSE20447 as it's already processed.\n",
      "Skipping CB.EN.U4CSE20449 as it's already processed.\n",
      "Skipping CB.EN.U4CSE21002 as it's already processed.\n",
      "Skipping CB.EN.U4CSE21014 as it's already processed.\n",
      "Skipping CB.EN.U4CSE21015 as it's already processed.\n",
      "Skipping CB.EN.U4CSE21020 as it's already processed.\n",
      "Skipping CB.EN.U4CSE21023 as it's already processed.\n",
      "Skipping CB.EN.U4CSE21045 as it's already processed.\n",
      "Skipping CB.EN.U4CSE21050 as it's already processed.\n",
      "Skipping CB.EN.U4CSE21054 as it's already processed.\n",
      "Skipping CB.EN.U4CSE21060 as it's already processed.\n",
      "Skipping CB.EN.U4CSE21635 as it's already processed.\n",
      "Skipping CB.EN.U4CSE22011 as it's already processed.\n",
      "Skipping CB.EN.U4CSE22301 as it's already processed.\n",
      "Skipping CB.EN.U4CSE22304 as it's already processed.\n",
      "Skipping CB.EN.U4CSE22308 as it's already processed.\n",
      "Skipping CB.EN.U4CSE22312 as it's already processed.\n",
      "Skipping CB.EN.U4CSE22323 as it's already processed.\n",
      "Skipping CB.EN.U4CSE22351 as it's already processed.\n",
      "Skipping CB.EN.U4CSE22356 as it's already processed.\n",
      "Skipping CB.EN.U4CSE22437 as it's already processed.\n",
      "Skipping CB.EN.U4CSE22443 as it's already processed.\n",
      "Skipping CB.EN.U4EEE23022 as it's already processed.\n",
      "Skipping CB.EN.U4EEE23044 as it's already processed.\n",
      "Skipping CB.EN.U4EEE23107 as it's already processed.\n",
      "Skipping CB.EN.U4EEE23113 as it's already processed.\n",
      "Skipping CB.EN.U4EEE23119 as it's already processed.\n",
      "Skipping CB.EN.U4EEE23121 as it's already processed.\n",
      "Skipping CB.EN.U4EEE23125 as it's already processed.\n",
      "Skipping CB.EN.U4EEE23128 as it's already processed.\n",
      "Skipping CB.EN.U4EEE23135 as it's already processed.\n",
      "Skipping CB.EN.U4EEE23137 as it's already processed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import storage\n",
    "import sys\n",
    "import json\n",
    "\n",
    "def read_finished_rollnos(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return set(line.strip() for line in file)\n",
    "    except FileNotFoundError:\n",
    "        return set()\n",
    "\n",
    "def write_finished_rollno(file_path, rollno):\n",
    "    with open(file_path, 'a') as file:\n",
    "        file.write(rollno + '\\n')\n",
    "\n",
    "def upload_to_gcs(bucket_name, local_file_path, remote_file_path, key_json_path):\n",
    "    # Instantiate a client using your service account key\n",
    "    client = storage.Client.from_service_account_json(key_json_path)\n",
    "\n",
    "    # Get the bucket\n",
    "    bucket = client.bucket(bucket_name)\n",
    "\n",
    "    # Upload the file to GCS\n",
    "    blob = bucket.blob(remote_file_path)\n",
    "    blob.upload_from_filename(local_file_path)\n",
    "\n",
    "    print(f\"File {local_file_path} uploaded to {bucket_name}/{remote_file_path}.\")\n",
    "\n",
    "def GaussianMask(sizex, sizey, sigma=33, center=None, fix=1):\n",
    "    \"\"\"\n",
    "    sizex  : mask width\n",
    "    sizey  : mask height\n",
    "    sigma  : gaussian Sd\n",
    "    center : gaussian mean\n",
    "    fix    : gaussian max\n",
    "    return gaussian mask\n",
    "    \"\"\"\n",
    "    x = np.arange(0, sizex, 1, float)\n",
    "    y = np.arange(0, sizey, 1, float)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "\n",
    "    if center is None:\n",
    "        x0 = sizex // 2\n",
    "        y0 = sizey // 2\n",
    "    else:\n",
    "        if np.isnan(center[0]) == False and np.isnan(center[1]) == False:\n",
    "            x0 = center[0]\n",
    "            y0 = center[1]\n",
    "        else:\n",
    "            return np.zeros((sizey, sizex))\n",
    "\n",
    "    return fix * np.exp(-4 * np.log(2) * ((x - x0) ** 2 + (y - y0) ** 2) / sigma ** 2)\n",
    "\n",
    "def Fixpos2Densemap(fix_arr, width, height, imgfile, alpha=0.5, threshold=10):\n",
    "    \"\"\"\n",
    "    fix_arr   : fixation array number of subjects x 3(x,y,fixation)\n",
    "    width     : output image width\n",
    "    height    : output image height\n",
    "    imgfile   : image file (optional)\n",
    "    alpha     : merge rate imgfile and heatmap (optional)\n",
    "    threshold : heatmap threshold (0~255)\n",
    "    return heatmap \n",
    "    \"\"\"\n",
    "\n",
    "    heatmap = np.zeros((height, width), np.float32)\n",
    "    for n_subject in tqdm(range(fix_arr.shape[0])):\n",
    "        heatmap += GaussianMask(width, height, 33, (fix_arr[n_subject, 0], fix_arr[n_subject, 1]),\n",
    "                                fix_arr[n_subject, 2])\n",
    "\n",
    "    # Normalization\n",
    "    heatmap = heatmap / np.amax(heatmap)\n",
    "    heatmap = heatmap * 255\n",
    "    heatmap = heatmap.astype(\"uint8\")\n",
    "\n",
    "    if imgfile.any():\n",
    "        # Resize heatmap to imgfile shape \n",
    "        h, w, _ = imgfile.shape\n",
    "        heatmap = cv2.resize(heatmap, (w, h))\n",
    "        heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "        # Create mask\n",
    "        mask = np.where(heatmap <= threshold, 1, 0)\n",
    "        mask = np.reshape(mask, (h, w, 1))\n",
    "        mask = np.repeat(mask, 3, axis=2)\n",
    "\n",
    "        # Merge images\n",
    "        marge = imgfile * mask + heatmap_color * (1 - mask)\n",
    "        marge = marge.astype(\"uint8\")\n",
    "        marge = cv2.addWeighted(imgfile, 1 - alpha, marge, alpha, 0)\n",
    "        return marge\n",
    "\n",
    "    else:\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        return heatmap\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Connect to MongoDB\n",
    "\n",
    "    with open('../config.json') as f:\n",
    "        config = json.load(f)\n",
    "        mongo_uri = config['MONGO_URI']\n",
    "\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client['INTUX']\n",
    "    collection = db['GazeData']\n",
    "\n",
    "    # Get distinct roll numbers from MetaData collection\n",
    "    roll_nos = db['MetaData'].distinct(\"rollNo\")\n",
    "\n",
    "    # Load image file\n",
    "    img = cv2.imread('sample.png')\n",
    "\n",
    "    finished_rollnos = read_finished_rollnos('finished.txt')\n",
    "\n",
    "    for rollNo in roll_nos:\n",
    "\n",
    "        if rollNo in finished_rollnos:\n",
    "            print(f\"Skipping {rollNo} as it's already processed.\")\n",
    "            continue\n",
    "\n",
    "        # Fetch fixation data from MongoDB\n",
    "        fixation_data = collection.find({\"rollNo\": rollNo}, {'normalizedX': 1, 'normalizedY': 1, 'fixation': 1})\n",
    "\n",
    "        # Convert fixation data to numpy array\n",
    "        fix_arr = []\n",
    "        for entry in fixation_data:\n",
    "            normalizedX = entry.get('normalizedX', None)\n",
    "            normalizedY = entry.get('normalizedY', None)\n",
    "            fixation = entry.get('fixation', 100)  # Default value set to 100 if 'fixation' field is not present\n",
    "            if normalizedX is not None and normalizedY is not None:\n",
    "                fix_arr.append([normalizedX, normalizedY, fixation])\n",
    "        fix_arr = np.array(fix_arr)\n",
    "\n",
    "        # Normalize fixation data if needed\n",
    "        num_subjects = fix_arr.shape[0]\n",
    "        H, W, _ = img.shape\n",
    "        fix_arr[:, 0] *= W\n",
    "        fix_arr[:, 1] *= H\n",
    "\n",
    "        # Create heatmap\n",
    "        heatmap = Fixpos2Densemap(fix_arr, W, H, img, 0.7, 5)\n",
    "        cv2.imwrite(f\"{rollNo}.png\", heatmap)\n",
    "\n",
    "        # Upload the image to Google Cloud Storage\n",
    "        bucket_name = 'intux_fixation'  # Replace with your bucket name\n",
    "        key_json_path = \"finalyear-409412-5412169777f2.json\"  # Replace with your service account key JSON path\n",
    "        remote_file_path = f'{rollNo}.png'  # Remote file path in your bucket\n",
    "        upload_to_gcs(bucket_name, f\"{rollNo}.png\", remote_file_path, key_json_path)\n",
    "\n",
    "        write_finished_rollno('finished.txt', rollNo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
